{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.49.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (0.28.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\vanvi\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.8.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vanvi\\appdata\\roaming\\python\\python313\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vanvi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "! pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle imports\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import data_jaccard\n",
    "import data_minhash\n",
    "import sentence_bert\n",
    "import tdidf_vectorizer\n",
    "from tkinter import ttk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # load data for new data\n",
    "    news_data2 = pd.read_csv('sentiment_news_data2.csv')\n",
    "\n",
    "    # for empty strings replace with NaN\n",
    "    news_data2 = news_data2.fillna('')\n",
    "\n",
    "    all_entries = []\n",
    "\n",
    "    # loop and add entry/entries to the list\n",
    "    for i in range(1, 26):\n",
    "        # get top 1 to 25 for top, sen_top, date\n",
    "        col  = f'Top{i}'\n",
    "        col2 = f'Sen_Top{i}'\n",
    "        col3 = f'Date'\n",
    "        col_data = news_data2[col]\n",
    "        col_data2 = news_data2[col2]\n",
    "        col_data3 = news_data2[col3]\n",
    "        # loop to add append this data\n",
    "        for j in range(len(col_data)):\n",
    "            all_entries.append([col_data[j], col_data2[j], col_data3[j]])\n",
    "    return all_entries\n",
    "\n",
    "# print(all_entries[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stock data from file\n",
    "def load_stock_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    return data\n",
    "\n",
    "# setup function to get top stocks delta(s) provided a date, dataset, and day range\n",
    "def get_top_stocks(date, stock_data, days):\n",
    "    # convert date\n",
    "    stock_data['Date'] = pd.to_datetime(stock_data['Date'])\n",
    "\n",
    "    # get start and end dates, within a week\n",
    "    start = pd.to_datetime(date)\n",
    "    end   = start + pd.Timedelta(days=days) # could make days a selection in the menu that is passed to this function\n",
    "\n",
    "    #print(start)\n",
    "    #print(end)\n",
    "\n",
    "    filtered_data = stock_data[(stock_data['Date'] >= start) & (stock_data['Date'] <= end)]\n",
    "\n",
    "    #print(filtered_data)\n",
    "\n",
    "    # calculate stock change or delta\n",
    "    # last element minus first element, remove index\n",
    "    stock_delta = filtered_data.groupby('Stocks').apply(lambda x: x.iloc[-1]['Close'] - x.iloc[0]['Close']).reset_index()\n",
    "    stock_delta.columns = ['Stocks', 'Close_Delta']\n",
    "\n",
    "    #print(stock_delta)    \n",
    "\n",
    "    # sort for top ten deltas to return\n",
    "    neg_delta = stock_delta[stock_delta['Close_Delta'] < 0]\n",
    "    neg_ret = neg_delta.sort_values(by='Close_Delta', ascending=True).head(10)\n",
    "\n",
    "    pos_delta = stock_delta[stock_delta['Close_Delta'] > 0]\n",
    "    pos_ret = pos_delta.sort_values(by='Close_Delta', ascending=False).head(10)\n",
    "\n",
    "    return pos_ret, neg_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stock csv file\n",
    "stock_data = load_stock_data('updated_stock_data.csv')\n",
    "\n",
    "# test example\n",
    "test = False\n",
    "\n",
    "if test:\n",
    "    # use function to get the top stocks\n",
    "    test_date = '2018-11-11'\n",
    "    top_pos, top_neg = get_top_stocks(test_date, stock_data, 7)\n",
    "    print(top_pos)\n",
    "    print(\"\\n\")\n",
    "    print(top_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jaccard sim\n",
    "def jac_sim(headline, *args):\n",
    "    # load data\n",
    "    all_entries = load_data()\n",
    "    # apply jaccard sim\n",
    "    jac_ret = data_jaccard.jac_sim(all_entries, [str(headline)], 5, 10)\n",
    "    #print(jac_ret)\n",
    "    # handle return for top ten results\n",
    "    ret_val = []\n",
    "    for i in range(10):\n",
    "        ret_val.append((all_entries[jac_ret[i][0]][2], all_entries[jac_ret[i][0]][0], jac_ret[i][1], all_entries[jac_ret[i][0]][1]))\n",
    "    return ret_val\n",
    "\n",
    "\n",
    "# min hash\n",
    "def min_hash(headline, *args):\n",
    "    # load data\n",
    "    all_entries = load_data()\n",
    "    # apply min hash\n",
    "    min_ret = data_minhash.min_hash(all_entries, [str(headline)], 5, 10, 10)\n",
    "    # handle return for top ten results\n",
    "    ret_val = []\n",
    "    for i in range(10):\n",
    "        ret_val.append((all_entries[min_ret[i][1]][2], all_entries[min_ret[i][1]][0], min_ret[i][0],all_entries[min_ret[i][1]][1]))\n",
    "    return ret_val\n",
    "\n",
    "\n",
    "# tdidf vectorizer\n",
    "def td_idf(headline, *args):\n",
    "    # load in data\n",
    "    news_data2 = pd.read_csv('sentiment_news_data2.csv')\n",
    "    news_data2 = news_data2.fillna('')\n",
    "    all_entries = []\n",
    "    for i in range(1, 26):\n",
    "        col = f'Top{i}'\n",
    "        col2 = f'Sen_Top{i}'\n",
    "        for j in range(len(news_data2[col])):\n",
    "            all_entries.append([news_data2['Date'][j], news_data2[col][j], news_data2[col2][j]])\n",
    "\n",
    "    database = pd.DataFrame(data={\n",
    "                                'Date'          : [row[0] for row in all_entries],\n",
    "                                'News_Headlines': [row[1] for row in all_entries],\n",
    "                                'Sentiment'     : [row[2] for row in all_entries]\n",
    "                                })\n",
    "\n",
    "    # apply td-idf vectorizer\n",
    "    vectorizer = TfidfVectorizer(norm='l2')\n",
    "    newsValues = database['News_Headlines'].values\n",
    "    mtx = vectorizer.fit_transform(newsValues)\n",
    "    mtx.shape\n",
    "    td_ret = tdidf_vectorizer.vector_search(str(headline), vectorizer, mtx, database, k=10)\n",
    "\n",
    "    # return top ten results\n",
    "    ret_val = []\n",
    "    for i in range(10):\n",
    "        ret_val.append((td_ret[i][1], str(td_ret[i][2]), str(td_ret[i][3]), str(td_ret[i][4])))\n",
    "\n",
    "    return ret_val\n",
    "\n",
    "\n",
    "# sentence bert\n",
    "def sen_bert(headline, *args):\n",
    "    # load in data\n",
    "    all_entries = load_data()\n",
    "    # apply sentence bert\n",
    "    bert_ret = sentence_bert.sent_bert(all_entries, [str(headline)], 10, 'all_embed.npy')\n",
    "    # return top ten results\n",
    "    ret_val = []\n",
    "    for i in range(10):\n",
    "        ret_val.append((all_entries[bert_ret[i][0]][2], all_entries[bert_ret[i][0]][0], bert_ret[i][2], all_entries[bert_ret[i][0]][1]))\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search headline query\n",
    "def process_headline(headline, method):\n",
    "    methods = {\n",
    "                \"Jaccard\" : jac_sim,\n",
    "                \"MinHash\" : min_hash,\n",
    "                \"TF-IDF\"  : td_idf,\n",
    "                \"BERT\"    : sen_bert,\n",
    "              }\n",
    "\n",
    "    # check if valid\n",
    "    if method in methods:\n",
    "        # process data for return\n",
    "        method_func = methods[method]\n",
    "        result      = method_func(headline)\n",
    "        ret_val = ''\n",
    "        for i in range(10):\n",
    "            ret_val = ret_val + result[i][0] + str(\", \") + result[i][1]  + str(\", \") + str(result[i][2]) + str(\", \") + str(result[i][3]) + str(\"\\n\")\n",
    "        return result\n",
    "    else:\n",
    "        return \"Error\"\n",
    "\n",
    "\n",
    "# click function to update the list box\n",
    "def click():\n",
    "    method   = method_var.get()\n",
    "    headline = entry.get()\n",
    "\n",
    "    if headline:\n",
    "        result = process_headline([headline], method)\n",
    "        #print(result)\n",
    "        # [('3-May-20', 'important test wont involve swab temperature check'), ('3-Apr-21', 'detect fake news challenge test'), ...\n",
    "        display_res(result)\n",
    "    else:\n",
    "        messagebox.showwarning(\"Warning\", \"No headline entered.\")\n",
    "\n",
    "\n",
    "# function to open a new window\n",
    "def display_new(date, stock_data, days):\n",
    "    new_window = tk.Toplevel(root)\n",
    "    new_window.title(\"Stock Results\")\n",
    "\n",
    "    # convert date\n",
    "    stock_data['Date'] = pd.to_datetime(stock_data['Date'])\n",
    "\n",
    "    #print(stock_data[0:10])\n",
    "\n",
    "    top_pos, top_neg = get_top_stocks(date, stock_data, days)\n",
    "\n",
    "    #print(top_pos[0:10])\n",
    "    #print(top_neg[0:10])\n",
    "\n",
    "    # date header\n",
    "    date_label = tk.Label(new_window, text=f\"Search Date of {date}\")\n",
    "    date_label.pack(pady=10)\n",
    "\n",
    "    # setup frame(s) for delta(s)\n",
    "    pos_frame = tk.LabelFrame(new_window, text=\"Top Positive Stock Deltas\", padx=10, pady=10)\n",
    "    pos_frame.pack(padx=10, pady=10)\n",
    "    neg_frame = tk.LabelFrame(new_window, text=\"Top Negative Stock Deltas\", padx=10, pady=10)\n",
    "    neg_frame.pack(padx=10, pady=10)\n",
    "\n",
    "    # treeview for delta(s)\n",
    "    pos_tree = ttk.Treeview(pos_frame, columns=(\"Stock\", \"Delta\"), show='headings')\n",
    "    pos_tree.heading(\"Stock\", text=\"Stock\")\n",
    "    pos_tree.heading(\"Delta\", text=\"Close Delta Over Range\")\n",
    "    pos_tree.pack(fill=\"both\", expand=True)\n",
    "    neg_tree = ttk.Treeview(neg_frame, columns=(\"Stock\", \"Delta\"), show='headings')\n",
    "    neg_tree.heading(\"Stock\", text=\"Stock\")\n",
    "    neg_tree.heading(\"Delta\", text=\"Close Delta Over Range\")\n",
    "    neg_tree.pack(fill=\"both\", expand=True)\n",
    "\n",
    "    # input data to treeview(s)\n",
    "    for i, row in top_pos.iterrows():\n",
    "        #print(row['Stocks'])\n",
    "        #print(row['Close_Delta'])\n",
    "        pos_tree.insert(\"\", \"end\", values=(row['Stocks'], row['Close_Delta']))\n",
    "    for i, row in top_neg.iterrows():\n",
    "        neg_tree.insert(\"\", \"end\", values=(row['Stocks'], row['Close_Delta']))\n",
    "\n",
    "\n",
    "# function to select from date\n",
    "def select_date(event):\n",
    "    # event seems to be needed, but not used by me\n",
    "    #print(event)\n",
    "    selection = result_treeview.selection()\n",
    "    selected_item = result_treeview.item(selection[0])['values']\n",
    "    days = int(range_var.get())\n",
    "    # open new window\n",
    "    display_new(selected_item[0], stock_data, days)\n",
    "\n",
    "\n",
    "# function to output or display results\n",
    "def display_res(results):\n",
    "    # # print(\"display : \" + str(results))\n",
    "\n",
    "    # delete old results\n",
    "    result_treeview.delete(*result_treeview.get_children())\n",
    "\n",
    "    # loop through results to display date and headline\n",
    "    for i in results:\n",
    "        result_treeview.insert(\"\", \"end\", values=(i[0], i[1], i[2], i[3]))\n",
    "\n",
    "\n",
    "# load in data\n",
    "filepath = 'updated_stock_data.csv'\n",
    "stock_data = load_stock_data(filepath)\n",
    "\n",
    "# setup tk root\n",
    "root = tk.Tk()\n",
    "root.title(\"Headline Query for Stock Analysis\")\n",
    "# setup headline query\n",
    "entry_label = tk.Label(root, text=\"Enter Headline Query:\")\n",
    "entry_label.pack(pady=10)\n",
    "\n",
    "# setup query input\n",
    "entry = tk.Entry(root, width=200)\n",
    "entry.pack(pady=10)\n",
    "\n",
    "# dropdown menu\n",
    "method_label = tk.Label(root, text=\"Select Processing Method:\")\n",
    "method_label.pack(pady=10)\n",
    "method_var = tk.StringVar()\n",
    "method_var.set(\"BERT\") # default value\n",
    "methods_dropdown = tk.OptionMenu(root, method_var, \"Jaccard\", \"MinHash\", \"TF-IDF\", \"BERT\")\n",
    "methods_dropdown.pack(pady=10)\n",
    "\n",
    "# setup the search button\n",
    "process_button = tk.Button(root, text=\"Search\", command=click)\n",
    "process_button.pack(pady=10)\n",
    "\n",
    "# Dropdown menu for range\n",
    "range_label = tk.Label(root, text=\"Select Range (Days):\")\n",
    "range_label.pack(pady=2)\n",
    "# default value for range\n",
    "range_var = tk.StringVar()\n",
    "range_var.set(\"7\")\n",
    "range_dropdown = tk.OptionMenu(root, range_var, *[str(i) for i in range(1, 31)])\n",
    "range_dropdown.pack(pady=2)\n",
    "\n",
    "# instructions for selecting headline(s) results\n",
    "info_label = tk.Label(root, text=\"Click on the headline(s) results to display stock information\")\n",
    "info_label.pack(pady=2)\n",
    "\n",
    "# search results\n",
    "res_label = tk.Label(root, text=\"\")\n",
    "res_label.pack(pady=2)\n",
    "\n",
    "# create treeview for displaying results\n",
    "result_treeview = ttk.Treeview(root, columns=(\"Date\", \"Headline\", \"Score\", \"Sentiment\"), show='headings')\n",
    "result_treeview.heading(\"Date\", text=\"Date\")\n",
    "result_treeview.column(\"Date\", width=100)\n",
    "result_treeview.heading(\"Headline\", text=\"Headline\")\n",
    "result_treeview.column(\"Headline\", width=900)\n",
    "result_treeview.heading(\"Score\", text=\"Score\")\n",
    "result_treeview.column(\"Score\", width=100)\n",
    "result_treeview.heading(\"Sentiment\", text=\"Sentiment\")\n",
    "result_treeview.column(\"Sentiment\", width=100)\n",
    "result_treeview.pack(pady=2, fill=\"both\")\n",
    "result_treeview.bind('<<TreeviewSelect>>', select_date)\n",
    "\n",
    "# main loop\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
