{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.4.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (4.49.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (1.15.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (0.29.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vanvi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "! pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle imports\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import data_jaccard\n",
    "import data_minhash\n",
    "import sentence_bert\n",
    "import tdidf_vectorizer\n",
    "from tkinter import ttk\n",
    "# from data_jaccard import jac_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # load data\n",
    "    news_data2 = pd.read_csv('sentiment_news_data2.csv')\n",
    "\n",
    "    # for empty strings replace with NaN\n",
    "    news_data2 = news_data2.fillna('')\n",
    "\n",
    "    all_entries = []\n",
    "\n",
    "    # loop and add entry/entries to the list\n",
    "    #for col in [f'Top{i}' for i in range(1, 26)]:\n",
    "    for i in range(1, 26):\n",
    "        # get top 1 to 25\n",
    "        col  = f'Top{i}'\n",
    "        col2 = f'Sen_Top{i}'\n",
    "        col3 = f'Date'\n",
    "        col_data = news_data2[col]\n",
    "        col_data2 = news_data2[col2]\n",
    "        col_data3 = news_data2[col3]\n",
    "        #for item in col_data:\n",
    "        for j in range(len(col_data)):\n",
    "            #all_entries.append([item]) \n",
    "            #all_entries.append([item, col_data2])\n",
    "            #all_entries.append([col_data[j], col_data2[j]])\n",
    "            all_entries.append([col_data[j], col_data2[j], col_data3[j]])\n",
    "    \n",
    "    return all_entries\n",
    "\n",
    "# print(all_entries[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stock_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    return data\n",
    "\n",
    "def get_top_stocks(date, stock_data, days):\n",
    "    # convert date\n",
    "    stock_data['Date'] = pd.to_datetime(stock_data['Date'])\n",
    "\n",
    "    # get start and end dates, within a week\n",
    "    start = pd.to_datetime(date)\n",
    "    end   = start + pd.Timedelta(days=days) # could make days a selection in the menu that is passed to this function\n",
    "\n",
    "    #print(start)\n",
    "    #print(end)\n",
    "    # 2020-05-03 00:00:00\n",
    "    # 2020-05-10 00:00:00\n",
    "\n",
    "    # this one will error\n",
    "    # 2023-04-18 00:00:00\n",
    "    # 2023-04-25 00:00:00\n",
    "    # idk why\n",
    "    # 17-Apr-23\n",
    "    # 18-Apr-23\n",
    "    # 19-Apr-23\n",
    "    # 20-Apr-23\n",
    "    # 21-Apr-23\n",
    "    # 22-Apr-23\n",
    "    # 23-Apr-23\n",
    "    # 24-Apr-23\n",
    "    # 25-Apr-23\n",
    "    # 26-Apr-23\n",
    "\n",
    "    # ah it is because results don't go past  2023-04-23\n",
    "    # nvm same issue\n",
    "\n",
    "    #if end > pd.to_datetime(2022-12-12):\n",
    "    #    end = pd.to_datetime(2022-12-12)\n",
    "\n",
    "    # usually returns back pandas data frame\n",
    "    # error will show \n",
    "    #   Empty DataFrame\n",
    "    #   Columns: [Unnamed: 0, Date, Low, Open, Volume, High, Close, Adjusted Close, Stocks]\n",
    "    #   Index: []\n",
    "\n",
    "    # fixed it, it was the range of the sentiment data that had to be cut down smaller than expected, since stocks only go up to 2022-12-12\n",
    "    #print(start)\n",
    "    #print(end)\n",
    "\n",
    "    filtered_data = stock_data[(stock_data['Date'] >= start) & (stock_data['Date'] <= end)]\n",
    "\n",
    "    #print(filtered_data)\n",
    "\n",
    "    # calculate stock change or delta\n",
    "    # last element minus first element, remove index\n",
    "    stock_delta = filtered_data.groupby('Stocks').apply(lambda x: x.iloc[-1]['Close'] - x.iloc[0]['Close']).reset_index()\n",
    "    stock_delta.columns = ['Stocks', 'Close_Delta']\n",
    "\n",
    "    #print(stock_delta)    \n",
    "\n",
    "    # sort for top ten deltas to return\n",
    "    neg_delta = stock_delta[stock_delta['Close_Delta'] < 0]\n",
    "    neg_ret = neg_delta.sort_values(by='Close_Delta', ascending=True).head(10)\n",
    "\n",
    "    pos_delta = stock_delta[stock_delta['Close_Delta'] > 0]\n",
    "    pos_ret = pos_delta.sort_values(by='Close_Delta', ascending=False).head(10)\n",
    "\n",
    "    return pos_ret, neg_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Stocks  Close_Delta\n",
      "452   BRK-A  5310.000000\n",
      "1194    FPT   727.203125\n",
      "3172   VRTB   500.000000\n",
      "1213   FSFF   135.000000\n",
      "559    CCUR   120.120117\n",
      "2187    NVR    77.540039\n",
      "2623  SAUHF    65.849976\n",
      "948     DXM    54.160156\n",
      "303     AZO    35.390015\n",
      "2483   QTNT    30.800018\n",
      "\n",
      "\n",
      "     Stocks  Close_Delta\n",
      "2978   TOPS -1800.000000\n",
      "462     BSI  -272.709961\n",
      "1292   GLBS  -226.000000\n",
      "2973   TNXP  -192.000000\n",
      "2181   NVCN  -125.000000\n",
      "493   BYCBF   -52.859985\n",
      "2692  SGSOF   -50.000000\n",
      "2664  SEBYF   -44.899994\n",
      "62     ADXS   -36.479797\n",
      "2360  PGPHF   -33.149963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanvi\\AppData\\Local\\Temp\\ipykernel_27448\\1090658075.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  stock_delta = filtered_data.groupby('Stocks').apply(lambda x: x.iloc[-1]['Close'] - x.iloc[0]['Close']).reset_index()\n"
     ]
    }
   ],
   "source": [
    "# load stock csv file\n",
    "stock_data = load_stock_data('updated_stock_data.csv')\n",
    "\n",
    "# use function to get the top stocks\n",
    "test_date = '2018-11-11'\n",
    "top_pos, top_neg = get_top_stocks(test_date, stock_data, 7)\n",
    "print(top_pos)\n",
    "print(\"\\n\")\n",
    "print(top_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup accessor functions to other python files\n",
    "def jac_sim(headline, *args):\n",
    "    # Replace with actual implementation\n",
    "\n",
    "    all_entries = load_data()\n",
    "\n",
    "    jac_ret = data_jaccard.jac_sim(all_entries, [str(headline)], 5, 10)\n",
    "\n",
    "    ret_val = []\n",
    "    for i in range(10):\n",
    "        #ret_val.append(all_entries[jac_ret[i][0]][0])\n",
    "        #ret_val.append((all_entries[jac_ret[i][0]][0], all_entries[jac_ret[i][0]][2]))\n",
    "        ret_val.append((all_entries[jac_ret[i][0]][2], all_entries[jac_ret[i][0]][0], all_entries[jac_ret[i][0]][1]))\n",
    "\n",
    "    return ret_val\n",
    "\n",
    "\n",
    "def min_hash(headline, *args):\n",
    "    all_entries = load_data()\n",
    "\n",
    "    min_ret = data_minhash.min_hash(all_entries, [str(headline)], 5, 10, 10)\n",
    "\n",
    "    ret_val = []\n",
    "    for i in range(10):\n",
    "        #ret_val.append(all_entries[min_ret[i][1]][0])\n",
    "        #ret_val.append((all_entries[min_ret[i][1]][0], all_entries[min_ret[i][1]][2]))\n",
    "        ret_val.append((all_entries[min_ret[i][1]][2], all_entries[min_ret[i][1]][0], all_entries[min_ret[i][1]][1]))\n",
    "\n",
    "    return ret_val\n",
    "\n",
    "\n",
    "def td_idf(headline, *args):\n",
    "    news_data2 = pd.read_csv('sentiment_news_data2.csv')\n",
    "    news_data2 = news_data2.fillna('')\n",
    "    all_entries = []\n",
    "    for i in range(1, 26):  # Columns: Top1 to Top25\n",
    "        col = f'Top{i}'\n",
    "        col2 = f'Sen_Top{i}'\n",
    "        for j in range(len(news_data2[col])):\n",
    "            all_entries.append([news_data2['Date'][j], news_data2[col][j], news_data2[col2][j]])\n",
    "\n",
    "    database = pd.DataFrame(data={\n",
    "        'Date': [row[0] for row in all_entries],\n",
    "        'News_Headlines': [row[1] for row in all_entries],\n",
    "        'Sentiment': [row[2] for row in all_entries]\n",
    "    })\n",
    "\n",
    "    vectorizer = TfidfVectorizer(norm='l2')\n",
    "    newsValues = database['News_Headlines'].values\n",
    "    mtx = vectorizer.fit_transform(newsValues)\n",
    "    mtx.shape\n",
    "\n",
    "    td_ret = tdidf_vectorizer.vector_search(str(headline), vectorizer, mtx, database, k=10)\n",
    "\n",
    "    ret_val = []\n",
    "    for i in range(10):\n",
    "        #ret_val.append(str(td_ret[i][2]))\n",
    "        #ret_val.append((td_ret[i][1], str(td_ret[i][2])))\n",
    "        ret_val.append((td_ret[i][1], str(td_ret[i][2]), str(td_ret[i][4])))\n",
    "\n",
    "    return ret_val\n",
    "\n",
    "\n",
    "def sen_bert(headline, *args):\n",
    "\n",
    "    all_entries = load_data()\n",
    "    bert_ret = sentence_bert.sent_bert(all_entries, [str(headline)], 10, 'all_embed.npy')\n",
    "    ret_val = []\n",
    "    for i in range(10):\n",
    "        #ret_val.append(all_entries[bert_ret[i][0]][0])\n",
    "        ret_val.append((all_entries[bert_ret[i][0]][2], all_entries[bert_ret[i][0]][0], all_entries[bert_ret[i][0]][1]))\n",
    "\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanvi\\AppData\\Local\\Temp\\ipykernel_27448\\1090658075.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  stock_delta = filtered_data.groupby('Stocks').apply(lambda x: x.iloc[-1]['Close'] - x.iloc[0]['Close']).reset_index()\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\tkinter\\__init__.py\", line 1967, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\vanvi\\AppData\\Local\\Temp\\ipykernel_27448\\1377798414.py\", line 95, in select_date\n",
      "    selected_item = result_treeview.item(selection[0])['values']\n",
      "                                         ~~~~~~~~~^^^\n",
      "IndexError: tuple index out of range\n",
      "C:\\Users\\vanvi\\AppData\\Local\\Temp\\ipykernel_27448\\1090658075.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  stock_delta = filtered_data.groupby('Stocks').apply(lambda x: x.iloc[-1]['Close'] - x.iloc[0]['Close']).reset_index()\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\tkinter\\__init__.py\", line 1967, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\vanvi\\AppData\\Local\\Temp\\ipykernel_27448\\1377798414.py\", line 95, in select_date\n",
      "    selected_item = result_treeview.item(selection[0])['values']\n",
      "                                         ~~~~~~~~~^^^\n",
      "IndexError: tuple index out of range\n",
      "C:\\Users\\vanvi\\AppData\\Local\\Temp\\ipykernel_27448\\1090658075.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  stock_delta = filtered_data.groupby('Stocks').apply(lambda x: x.iloc[-1]['Close'] - x.iloc[0]['Close']).reset_index()\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\tkinter\\__init__.py\", line 1967, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\vanvi\\AppData\\Local\\Temp\\ipykernel_27448\\1377798414.py\", line 95, in select_date\n",
      "    selected_item = result_treeview.item(selection[0])['values']\n",
      "                                         ~~~~~~~~~^^^\n",
      "IndexError: tuple index out of range\n",
      "C:\\Users\\vanvi\\AppData\\Local\\Temp\\ipykernel_27448\\1090658075.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  stock_delta = filtered_data.groupby('Stocks').apply(lambda x: x.iloc[-1]['Close'] - x.iloc[0]['Close']).reset_index()\n"
     ]
    }
   ],
   "source": [
    "# search headline query\n",
    "def process_headline(headline, method):\n",
    "    methods = {\n",
    "                \"Jaccard\" : jac_sim,\n",
    "                \"MinHash\" : min_hash,\n",
    "                \"TF-IDF\"  : td_idf,\n",
    "                \"BERT\"    : sen_bert,\n",
    "              }\n",
    "\n",
    "    # check if valid\n",
    "    if method in methods:\n",
    "        method_func = methods[method]\n",
    "        result = method_func(headline, 5, 10)\n",
    "\n",
    "        ret_val = ''\n",
    "\n",
    "        for i in range(10):\n",
    "            ret_val = ret_val + result[i][0] + str(\", \") + result[i][1]  + str(\", \") + str(result[i][2]) + str(\"\\n\")\n",
    "\n",
    "        #return ret_val\n",
    "        return result\n",
    "    else:\n",
    "        return \"Error\"\n",
    "\n",
    "\n",
    "# click function to update the list box\n",
    "def click():\n",
    "    method   = method_var.get()\n",
    "    headline = entry.get()\n",
    "\n",
    "    if headline:\n",
    "        result = process_headline([headline], method)\n",
    "        #print(result)\n",
    "        # [('3-May-20', 'important test wont involve swab temperature check'), ('3-Apr-21', 'detect fake news challenge test'), ...\n",
    "        display_res(result)\n",
    "    else:\n",
    "        messagebox.showwarning(\"Warning\", \"No headline entered.\")\n",
    "\n",
    "\n",
    "# function to open a new window\n",
    "def display_new(date, stock_data, days):\n",
    "    new_window = tk.Toplevel(root)\n",
    "    new_window.title(\"Stock Results\")\n",
    "\n",
    "    # convert date\n",
    "    stock_data['Date'] = pd.to_datetime(stock_data['Date'])\n",
    "\n",
    "    #print(stock_data[0:10])\n",
    "\n",
    "    # get top deltas\n",
    "    # need to look at this function more, something is breaking it here for some selections\n",
    "    top_pos, top_neg = get_top_stocks(date, stock_data, days)\n",
    "\n",
    "    #print(top_pos[0:10])\n",
    "    #print(top_neg[0:10])\n",
    "\n",
    "    # date header\n",
    "    date_label = tk.Label(new_window, text=f\"Search Date of {date}\")\n",
    "    date_label.pack(pady=10)\n",
    "\n",
    "    # setup frame(s) for delta(s)\n",
    "    pos_frame = tk.LabelFrame(new_window, text=\"Top Positive Stock Deltas\", padx=10, pady=10)\n",
    "    pos_frame.pack(padx=10, pady=10)\n",
    "    neg_frame = tk.LabelFrame(new_window, text=\"Top Negative Stock Deltas\", padx=10, pady=10)\n",
    "    neg_frame.pack(padx=10, pady=10)\n",
    "\n",
    "    # treeview for delta(s)\n",
    "    pos_tree = ttk.Treeview(pos_frame, columns=(\"Stock\", \"Delta\"), show='headings')\n",
    "    pos_tree.heading(\"Stock\", text=\"Stock\")\n",
    "    pos_tree.heading(\"Delta\", text=\"Close Delta Over Range\")\n",
    "    pos_tree.pack(fill=\"both\", expand=True)\n",
    "    neg_tree = ttk.Treeview(neg_frame, columns=(\"Stock\", \"Delta\"), show='headings')\n",
    "    neg_tree.heading(\"Stock\", text=\"Stock\")\n",
    "    neg_tree.heading(\"Delta\", text=\"Close Delta Over Range\")\n",
    "    neg_tree.pack(fill=\"both\", expand=True)\n",
    "\n",
    "    # input data to treeview(s)\n",
    "    for i, row in top_pos.iterrows():\n",
    "        #print(row['Stocks'])\n",
    "        #print(row['Close_Delta'])\n",
    "        pos_tree.insert(\"\", \"end\", values=(row['Stocks'], row['Close_Delta']))\n",
    "    for i, row in top_neg.iterrows():\n",
    "        neg_tree.insert(\"\", \"end\", values=(row['Stocks'], row['Close_Delta']))\n",
    "\n",
    "\n",
    "# function to select from date\n",
    "def select_date(event):\n",
    "    # event seems to be needed, but not used by me\n",
    "    #print(event)\n",
    "\n",
    "    #selection = result_listbox.curselection()\n",
    "    selection = result_treeview.selection()\n",
    "    # use date selection to open new window to display greatest stocks deltas for that date\n",
    "    #selected_item = result_listbox.get(selection[0])\n",
    "    selected_item = result_treeview.item(selection[0])['values']\n",
    "    #display_new(selected_item[0], stock_data)\n",
    "\n",
    "    days = int(range_var.get())\n",
    "    display_new(selected_item[0], stock_data, days)\n",
    "\n",
    "\n",
    "# function to output or display results\n",
    "def display_res(results):\n",
    "    # # print(\"display : \" + str(results))\n",
    "\n",
    "    # # delete old results\n",
    "    # result_listbox.delete(0, tk.END)\n",
    "    # # insert in new items\n",
    "    # for item in results:\n",
    "    #     result_listbox.insert(tk.END, item)\n",
    "\n",
    "    # delete old results\n",
    "    result_treeview.delete(*result_treeview.get_children())\n",
    "\n",
    "    # loop through results to display date and headline\n",
    "    for i in results:\n",
    "        result_treeview.insert(\"\", \"end\", values=(i[0], i[1], i[2]))\n",
    "\n",
    "\n",
    "\n",
    "filepath = 'updated_stock_data.csv'\n",
    "stock_data = load_stock_data(filepath)\n",
    "# apologies for the draft layout, I am not a UX designer\n",
    "\n",
    "# setup tk root\n",
    "root = tk.Tk()\n",
    "root.title(\"Headline Query for Stock Analysis\")\n",
    "# setup headline query\n",
    "entry_label = tk.Label(root, text=\"Enter Headline Query:\")\n",
    "entry_label.pack(pady=10)\n",
    "# dropdown menu\n",
    "method_label = tk.Label(root, text=\"Select Processing Method:\")\n",
    "method_label.pack(pady=10)\n",
    "method_var = tk.StringVar()\n",
    "method_var.set(\"BERT\") # default value\n",
    "methods_dropdown = tk.OptionMenu(root, method_var, \"Jaccard\", \"MinHash\", \"TF-IDF\", \"BERT\")\n",
    "methods_dropdown.pack(pady=10)\n",
    "# setup query input\n",
    "entry = tk.Entry(root, width=200)\n",
    "entry.pack(pady=10)\n",
    "# setup the search button\n",
    "process_button = tk.Button(root, text=\"Search\", command=click)\n",
    "process_button.pack(pady=10)\n",
    "\n",
    "\n",
    "# Dropdown menu for range\n",
    "range_label = tk.Label(root, text=\"Select Range (Days):\")\n",
    "range_label.pack(pady=2)\n",
    "# default value for range\n",
    "range_var = tk.StringVar()\n",
    "range_var.set(\"7\")\n",
    "range_dropdown = tk.OptionMenu(root, range_var, *[str(i) for i in range(1, 31)])\n",
    "range_dropdown.pack(pady=2)\n",
    "\n",
    "# instructions for selecting headline(s) results\n",
    "info_label = tk.Label(root, text=\"Click on the headline(s) results to display stock information\")\n",
    "info_label.pack(pady=2)\n",
    "\n",
    "# search results\n",
    "res_label = tk.Label(root, text=\"\")\n",
    "res_label.pack(pady=2)\n",
    "# display selectable results\n",
    "# result_listbox = tk.Listbox(root, width=200, height=10)\n",
    "# result_listbox.pack(pady=2)\n",
    "# # bind the selection to the select_date function\n",
    "# result_listbox.bind('<<ListboxSelect>>', select_date)\n",
    "\n",
    "# create treeview for displaying results\n",
    "result_treeview = ttk.Treeview(root, columns=(\"Date\", \"Headline\", \"Sentiment\"), show='headings')\n",
    "result_treeview.heading(\"Date\", text=\"Date\")\n",
    "result_treeview.column(\"Date\", width=100)\n",
    "result_treeview.heading(\"Headline\", text=\"Headline\")\n",
    "result_treeview.column(\"Headline\", width=900)\n",
    "result_treeview.heading(\"Sentiment\", text=\"Sentiment\")\n",
    "result_treeview.column(\"Sentiment\", width=100)\n",
    "result_treeview.pack(pady=2, fill=\"both\")\n",
    "result_treeview.bind('<<TreeviewSelect>>', select_date)\n",
    "\n",
    "# main loop\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
